{"version": "https://jsonfeed.org/version/1", "title": "langroid", "home_page_url": "https://langroid.github.io/langroid/", "feed_url": "https://langroid.github.io/langroid/feed_json_created.json", "description": "Langroid LLM App Development Framework", "icon": "https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Feed-icon.svg/128px-Feed-icon.svg.png", "authors": [], "language": "en", "items": [{"id": "https://langroid.github.io/langroid/blog/2024/01/18/langroid-knolwedge-graph-rag-powered-by-neo4j/", "url": "https://langroid.github.io/langroid/blog/2024/01/18/langroid-knolwedge-graph-rag-powered-by-neo4j/", "title": "Langroid: Knolwedge Graph RAG powered by Neo4j", "content_html": "<h2>\"Chat\" with various sources of information</h2>\n<p>LLMs are increasingly being used to let users converse in natural language with \na variety of types of data sou...</p>", "image": null, "date_published": "2024-01-18T00:00:00+00:00", "authors": [{"name": "mohannad"}], "tags": ["knowledge-graph", "langroid", "neo4j", "rag"]}, {"id": "https://langroid.github.io/langroid/blog/2023/09/19/language-models-completion-and-chat-completion/", "url": "https://langroid.github.io/langroid/blog/2023/09/19/language-models-completion-and-chat-completion/", "title": "Language Models: Completion and Chat-Completion", "content_html": "<p>Transformer-based language models are fundamentally next-token predictors, so \nnaturally all LLM APIs today at least provide a completion endpoint. \nIf an LLM is a next-token predictor, how could it possibly be used to \ngenerate a response to a question or instruction, or to engage in a conversation with \na human user? This is where the idea of \"chat-completion\" comes in.\nThis post is a refresher on the distinction between completion and chat-completion,\nand some interesting details on how chat-completion is implemented in practice.</p>", "image": null, "date_published": "2023-09-19T00:00:00+00:00", "authors": [{"name": "pchalasani"}], "tags": ["chat", "langroid", "llm", "local-llm"]}, {"id": "https://langroid.github.io/langroid/blog/2023/09/14/using-langroid-with-local-llms/", "url": "https://langroid.github.io/langroid/blog/2023/09/14/using-langroid-with-local-llms/", "title": "Using Langroid with Local LLMs", "content_html": "<h2>Why local models?</h2>\n<p>There are commercial, remotely served models that currently appear to beat all open/local\nmodels. So why care about local models? Local models are exciting for a number of reasons:</p>", "image": null, "date_published": "2023-09-14T00:00:00+00:00", "authors": [{"name": "pchalasani"}], "tags": ["langroid", "llm", "local-llm"]}, {"id": "https://langroid.github.io/langroid/blog/2023/09/03/langroid-harness-llms-with-multi-agent-programming/", "url": "https://langroid.github.io/langroid/blog/2023/09/03/langroid-harness-llms-with-multi-agent-programming/", "title": "Langroid: Harness LLMs with Multi-Agent Programming", "content_html": "<h1>Langroid: Harness LLMs with Multi-Agent Programming</h1>\n<h2>The LLM Opportunity</h2>\n<p>Given the remarkable abilities of recent Large Language Models (LLMs), there\nis an unprecedented opportunity to build intelligent applications powered by\nthis transformative technology. The top question for any enterprise is: how\nbest to harness the power of LLMs for complex applications? For technical and\npractical reasons, building LLM-powered applications is not as simple as\nthrowing a task at an LLM-system and expecting it to do it.</p>", "image": null, "date_published": "2023-09-03T00:00:00+00:00", "authors": [{"name": "pchalasani"}], "tags": ["langroid", "llm"]}]}